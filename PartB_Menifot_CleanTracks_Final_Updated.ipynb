{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f282d74b",
   "metadata": {},
   "source": [
    "\n",
    "# Part B â€” Menifot Clean Tracks (Final Submission, Updated)\n",
    "\n",
    "**Author:** Ashim Sharma  \n",
    "**Goal:**  \n",
    "Create a robust, label-free GPS spoofing (menifot) cleaning algorithm that:\n",
    "- Works on any dataset with time, lat, lon columns.  \n",
    "- Removes unrealistic motion points (spoofed).  \n",
    "- Optionally evaluates accuracy if ground-truth labels exist (even as YES/NO).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2141f0",
   "metadata": {},
   "source": [
    "## 1. Imports & Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af836fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import radians, sin, cos, asin, sqrt\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Compute great-circle distance between two points in kilometers.\"\"\"\n",
    "    lat1, lon1, lat2, lon2 = map(float, [lat1, lon1, lat2, lon2])\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat/2)**2 + cos(lat1)*cos(lat2)*sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    return 6371 * c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf244e1",
   "metadata": {},
   "source": [
    "## 2. Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8efb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_menifot(path):\n",
    "    df = pd.read_csv(path)\n",
    "    print(f\"\\nLoaded {path} with shape {df.shape}\")\n",
    "    print(\"Columns:\", list(df.columns))\n",
    "    display(df.head(3))\n",
    "    return df\n",
    "\n",
    "menifot1 = load_menifot(\"menifot1.csv\")\n",
    "menifot2 = load_menifot(\"menifot2.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a2f045",
   "metadata": {},
   "source": [
    "## 3. Detect Timestamp Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea48660",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_ts_col(df):\n",
    "    candidates = [\"timestamp\",\"time\",\"Time\",\"datetime\",\"Datetime\",\"DateTime\",\"date_time\"]\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    for c in df.columns:\n",
    "        try:\n",
    "            s = pd.to_datetime(df[c], errors=\"raise\")\n",
    "            if s.notna().mean() > 0.8:\n",
    "                return c\n",
    "        except Exception:\n",
    "            continue\n",
    "    raise KeyError(f\"No suitable timestamp column found in {list(df.columns)}\")\n",
    "\n",
    "print(\"menifot1 timestamp column:\", detect_ts_col(menifot1))\n",
    "print(\"menifot2 timestamp column:\", detect_ts_col(menifot2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e77c979",
   "metadata": {},
   "source": [
    "## 4. Detect Latitude/Longitude Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8b6367",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_lat_lon_cols(df):\n",
    "    lat_candidates = [\"lat\",\"Lat\",\"LAT\",\"latitude\",\"Latitude\"]\n",
    "    lon_candidates = [\"lon\",\"Lon\",\"LON\",\"long\",\"lng\",\"longitude\",\"Longitude\"]\n",
    "\n",
    "    lat_col = next((c for c in lat_candidates if c in df.columns), None)\n",
    "    lon_col = next((c for c in lon_candidates if c in df.columns), None)\n",
    "\n",
    "    if lat_col is None or lon_col is None:\n",
    "        raise KeyError(f\"Latitude/Longitude columns not found in {list(df.columns)}\")\n",
    "\n",
    "    print(f\"Detected lat column: {lat_col}, lon column: {lon_col}\")\n",
    "    return lat_col, lon_col\n",
    "\n",
    "detect_lat_lon_cols(menifot1)\n",
    "detect_lat_lon_cols(menifot2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b03e4",
   "metadata": {},
   "source": [
    "## 5. Clean Track Function (Final Robust Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3a77f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_track(\n",
    "    df,\n",
    "    lat_col=None,\n",
    "    lon_col=None,\n",
    "    ts_col=None,\n",
    "    min_dt_seconds=10,\n",
    "    min_jump_km=5.0,\n",
    "    speed_cap_knots_low=18,\n",
    "    speed_cap_knots_high=45,\n",
    "    iqr_factor=1.5,\n",
    "):\n",
    "    if ts_col is None:\n",
    "        ts_col = detect_ts_col(df)\n",
    "    if lat_col is None or lon_col is None:\n",
    "        lat_col, lon_col = detect_lat_lon_cols(df)\n",
    "\n",
    "    work = df.copy()\n",
    "    work[ts_col] = pd.to_datetime(work[ts_col])\n",
    "    work = work.sort_values(ts_col).reset_index(drop=True)\n",
    "\n",
    "    work[\"lat_prev\"] = work[lat_col].shift(1)\n",
    "    work[\"lon_prev\"] = work[lon_col].shift(1)\n",
    "    work[\"t_prev\"] = work[ts_col].shift(1)\n",
    "    work[\"lat_next\"] = work[lat_col].shift(-1)\n",
    "    work[\"lon_next\"] = work[lon_col].shift(-1)\n",
    "    work[\"t_next\"] = work[ts_col].shift(-1)\n",
    "\n",
    "    work[\"dt_prev_h\"] = (work[ts_col] - work[\"t_prev\"]).dt.total_seconds() / 3600.0\n",
    "    work[\"dt_next_h\"] = (work[\"t_next\"] - work[ts_col]).dt.total_seconds() / 3600.0\n",
    "\n",
    "    work[\"dist_prev_km\"] = work.apply(\n",
    "        lambda r: haversine_km(r[\"lat_prev\"], r[\"lon_prev\"], r[lat_col], r[lon_col]) if pd.notna(r[\"lat_prev\"]) else np.nan,\n",
    "        axis=1,\n",
    "    )\n",
    "    work[\"dist_next_km\"] = work.apply(\n",
    "        lambda r: haversine_km(r[lat_col], r[lon_col], r[\"lat_next\"], r[\"lon_next\"]) if pd.notna(r[\"lat_next\"]) else np.nan,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    def safe_speed(dist_km, dt_h):\n",
    "        return np.where(\n",
    "            (dt_h > (min_dt_seconds / 3600.0)) & (dt_h > 0),\n",
    "            dist_km / dt_h / 1.852,\n",
    "            np.nan,\n",
    "        )\n",
    "\n",
    "    work[\"speed_prev_knots\"] = safe_speed(work[\"dist_prev_km\"], work[\"dt_prev_h\"])\n",
    "    work[\"speed_next_knots\"] = safe_speed(work[\"dist_next_km\"], work[\"dt_next_h\"])\n",
    "\n",
    "    all_speeds = (\n",
    "        pd.concat([work[\"speed_prev_knots\"], work[\"speed_next_knots\"]])\n",
    "        .replace([np.inf, -np.inf], np.nan)\n",
    "        .dropna()\n",
    "    )\n",
    "\n",
    "    if len(all_speeds) == 0:\n",
    "        work[\"is_outlier_pred\"] = 0\n",
    "        return work.copy(), work\n",
    "\n",
    "    q1, q3 = np.percentile(all_speeds, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    iqr_upper = q3 + iqr_factor * iqr\n",
    "    p90 = np.percentile(all_speeds, 90)\n",
    "    raw_thr = max(p90, iqr_upper, speed_cap_knots_low)\n",
    "    speed_thr = float(np.clip(raw_thr, speed_cap_knots_low, speed_cap_knots_high))\n",
    "\n",
    "    cond_high_prev = (work[\"speed_prev_knots\"] > speed_thr) & (work[\"dist_prev_km\"] > min_jump_km)\n",
    "    cond_high_next = (work[\"speed_next_knots\"] > speed_thr) & (work[\"dist_next_km\"] > min_jump_km)\n",
    "    work[\"is_outlier_pred\"] = (cond_high_prev & cond_high_next).astype(int)\n",
    "\n",
    "    clean_df = work[work[\"is_outlier_pred\"] == 0].copy()\n",
    "    return clean_df, work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88974ba",
   "metadata": {},
   "source": [
    "## 6. Normalize YES/NO Labels for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144412f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_is_menifot(series):\n",
    "    s = series.astype(str).str.strip().str.upper()\n",
    "    mapping = {\"1\":1,\"YES\":1,\"Y\":1,\"TRUE\":1,\"T\":1,\"0\":0,\"NO\":0,\"N\":0,\"FALSE\":0,\"F\":0}\n",
    "    return s.map(mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4a5de9",
   "metadata": {},
   "source": [
    "## 7. Apply & Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3898889",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_and_report(df, name):\n",
    "    print(f\"\\n===== {name} =====\")\n",
    "    clean_df, full_df = clean_track(df)\n",
    "\n",
    "    total = len(full_df)\n",
    "    removed = int(full_df[\"is_outlier_pred\"].sum())\n",
    "    kept = len(clean_df)\n",
    "\n",
    "    print(f\"Total points: {total}\")\n",
    "    print(f\"Predicted spoofed removed: {removed} ({removed/total*100:.2f}%)\")\n",
    "    print(f\"Clean track points kept: {kept}\")\n",
    "\n",
    "    if \"is_menifot\" in full_df.columns:\n",
    "        gt_norm = normalize_is_menifot(full_df[\"is_menifot\"])\n",
    "        pred = full_df[\"is_outlier_pred\"].astype(int)\n",
    "        mask = gt_norm.isin([0, 1])\n",
    "        if mask.sum() == 0:\n",
    "            print(\"\\nWarning: Label column not interpretable, skipping eval.\")\n",
    "            return clean_df, full_df\n",
    "\n",
    "        gt = gt_norm[mask]\n",
    "        pred_eval = pred[mask]\n",
    "\n",
    "        tp = int(((pred_eval == 1) & (gt == 1)).sum())\n",
    "        fp = int(((pred_eval == 1) & (gt == 0)).sum())\n",
    "        fn = int(((pred_eval == 0) & (gt == 1)).sum())\n",
    "        tn = int(((pred_eval == 0) & (gt == 0)).sum())\n",
    "        acc = (tp + tn) / len(gt)\n",
    "        print(\"\\nEvaluation vs label:\")\n",
    "        print(f\"TP={tp}, FP={fp}, FN={fn}, TN={tn}, Accuracy={acc:.3f}\")\n",
    "    else:\n",
    "        print(\"No 'is_menifot' column; skipped evaluation.\")\n",
    "\n",
    "    return clean_df, full_df\n",
    "\n",
    "clean_meni1, meni1_full = apply_and_report(menifot1, \"menifot1\")\n",
    "clean_meni2, meni2_full = apply_and_report(menifot2, \"menifot2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff34373",
   "metadata": {},
   "source": [
    "## 8. Optional Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da426149",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_tracks(full_df, clean_df, lat_col=None, lon_col=None, title=\"Track Cleaning\"):\n",
    "    if lat_col is None or lon_col is None:\n",
    "        lat_col, lon_col = detect_lat_lon_cols(full_df)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(full_df[lon_col], full_df[lat_col], s=6, alpha=0.25, label=\"Original\")\n",
    "    plt.scatter(clean_df[lon_col], clean_df[lat_col], s=10, alpha=0.9, marker=\"x\", label=\"Cleaned\")\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
